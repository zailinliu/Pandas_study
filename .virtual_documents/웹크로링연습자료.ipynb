


import requests as rq
url = 'https://quotes.toscrape.com/'
quote = rq.get(url)
quote





quote.content[0:100]





from bs4 import BeautifulSoup as bs
quote_html = bs(quote.content, 'lxml')
quote_html





quote_div = quote_html.find('div', class_= 'quote')
quote_div





quote_div = quote_html.find_all('div', class_= 'quote')
quote_div






quote_span = quote_div[1].find_all('span', class_= 'text')
quote_span





quote_span[0].text





quote_text = quote_html.select('div.quote > span.text')
quote_text





quote_text_list = [i.text for i in quote_text]
quote_text_list





quote_author = quote_html.select('div.quote > span > small.author')
quote_author_text = [ i.text  for i in quote_author]
quote_author_text





quote_a = quote_html.select('div.quote > span > a')
quote_a





quote_a[0]['href']
quote_a_list = [ i['href'] for i in quote_a ]
quote_a_list





quote_a_list = ['https://quotes.toscrape.com' + i['href'] for i in quote_a ]
quote_a_list





import requests as rq
from bs4 import BeautifulSoup as bs
import time

text_list = [] # 명언 리스트
author_list = [] # 작가 리스트
infor_list = [] # 사이트 링크 리스트

for i in range(1, 101):
    url = f'https://quotes.toscrape.com/page/{i}/'
    quote = rq.get(url)
    quote_html = bs(quote.content, 'lxml')
    quote_text = quote_html.select('div.quote > span.text')
    quote_text_list = [i.text for i in quote_text]
    quote_author = quote_html.select('div.quote > span > small.author')
    quote_author_list = [ i.text  for i in quote_author]
    quote_a = quote_html.select('div.quote > span > a')
    quote_a_list = ['https://quotes.toscrape.com' + i['href'] for i in quote_a]

    if len(quote_text_list) > 0 :
        text_list.extend(quote_text_list)
        author_list.extend(quote_author_list)
        infor_list.extend(quote_a_list)
        time.sleep(1)
    else : 
        break





text_list
author_list
infor_list
import pandas as pd
df = pd.DataFrame({'text' : text_list, 'author' : author_list, 'infor' : infor_list})
df





# import requests as rq
# url = 'https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258'
# d = rq.get(url)
# d


# from bs4 import BeautifulSoup as bs
# d_html = bs(d.content, 'lxml')


    # d_text = d_html.select('ul.realtimeNewsList _replaceNewsLink > li.newsList top')
    # d_text_list = [i.text for i in d_text]
    # d_author = d_html.select('ul.realtimeNewsList _replaceNewsLink > li.newsList top > dl > dt.thumb > dd.articleSummary > span.press')
    # d_author_list = [ i.text  for i in d_author]
    # d_a = quote_html.select('ul.realtimeNewsList _replaceNewsLink > li.newsList top > dl > dt.thumb > a')
    # d_a_list = ['https://finance.naver.com' + i['href'] for i in d_a]


import requests as rq
url = 'https://finance.naver.com/news/news_list.nhn?mode=LSS2D&section_id=101&section_id2=258'
d = rq.get(url)

from bs4 import BeautifulSoup as bs
d_html = bs( d.content, 'lxml' )

d_a=d_html.select('dl > dd.articleSubject > a')
d_a





d_a[0]['title']





d_title = [i['title'] for i in d_a]
d_title


import pandas as pd
df = pd.DataFrame({'title' : d_title})
df





import pandas as pd
url = 'https://en.wikipedia.org/wiki/List_of_countries_by_stock_market_capitalization'
a = rq.get(url)





import requests as rq
from bs4 import BeautifulSoup as bs
import pandas as pd
url = 'https://kind.krx.co.kr/disclosure/todaydisclosure.do?method=searchTodayDisclosureMain&marketType=0' 
page_info = {}
rq.post()









